{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SMINT: Spatial Multi-Omics Integration","text":"<p>SMINT is a Python package for Spatial Multi-Omics Integration with enhanced segmentation capabilities and streamlined workflow.</p>"},{"location":"#overview","title":"Overview","text":"<p>SMINT provides a comprehensive toolkit for processing and analyzing spatial omics data, including:</p> <ul> <li>Multi-GPU cell segmentation for whole-slide images</li> <li>Distributed segmentation using Dask for improved performance</li> <li>Live segmentation monitoring with intuitive visualization tools</li> <li>Streamlined alignment workflow using ST Align</li> <li>Integration with R analysis scripts</li> <li>Comprehensive documentation with step-by-step guides</li> <li>HPC deployment scripts for SLURM-based clusters</li> </ul> <p></p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#enhanced-segmentation","title":"Enhanced Segmentation","text":"<ul> <li>Multi-GPU Support: Utilize multiple GPUs for faster processing of large whole-slide images</li> <li>Distributed Computing: Use Dask to distribute segmentation tasks across multiple nodes</li> <li>Live Monitoring: Track segmentation progress in real-time with the built-in viewer</li> <li>Adaptive Segmentation: Automatically adjust segmentation parameters for optimal results</li> <li>Dual-Model Segmentation: Simultaneously segment cells and nuclei with specialized models</li> </ul>"},{"location":"#streamlined-alignment","title":"Streamlined Alignment","text":"<ul> <li>ST Align Integration: Seamlessly align spatial transcriptomics data with the ST Align tool</li> <li>Multiple Transformation Types: Support for affine, rigid, similarity, and projective transformations</li> <li>Multiple Data Types: Compatible with Visium, Slide-seq, and custom spatial data formats</li> </ul>"},{"location":"#r-integration","title":"R Integration","text":"<ul> <li>Seamless Python-R Bridge: Call R scripts and functions directly from Python</li> <li>Data Transfer: Convert data between Python and R formats</li> <li>Existing R Scripts: Use your existing R analysis scripts within the SMINT workflow</li> </ul>"},{"location":"#visualization","title":"Visualization","text":"<ul> <li>Live Viewer: Monitor segmentation progress with a live viewer</li> <li>Segmentation Overlays: Visualize segmentation results overlaid on the original image</li> <li>Feature Plots: Generate feature plots and spatial heatmaps</li> </ul>"},{"location":"#hpc-deployment","title":"HPC Deployment","text":"<ul> <li>SLURM Integration: Ready-to-use SLURM submission scripts for HPC deployment</li> <li>Resource Management: Optimized resource allocation for different processing stages</li> <li>Checkpointing: Resume processing from checkpoints after interruptions</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation: Install SMINT and its dependencies</li> <li>Segmentation: Run cell segmentation on whole-slide images</li> <li>Alignment: Align spatial transcriptomics data</li> <li>R Integration: Use R scripts and functions with SMINT</li> <li>Examples: Complete examples of SMINT workflows</li> <li>Configuration: Configure SMINT for your specific needs</li> <li>HPC Deployment: Run SMINT on HPC clusters</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use SMINT in your research, please cite:</p>"},{"location":"alignment/","title":"Spatial Alignment","text":"<p>SMINT provides a streamlined workflow for aligning different types of spatial omics data using the ST Align algorithm. This guide covers the complete alignment process, from data preparation to result validation.</p>"},{"location":"alignment/#overview-of-alignment-workflow","title":"Overview of Alignment Workflow","text":"<p>The SMINT alignment pipeline consists of these key stages:</p> <ol> <li>Data Preparation - Converting and preprocessing spatial data</li> <li>Reference Selection - Choosing appropriate reference points</li> <li>Alignment Computation - Calculating the optimal transformation</li> <li>Transform Application - Applying the transformation to target data</li> <li>Validation &amp; Quality Control - Assessing alignment accuracy</li> </ol>"},{"location":"alignment/#input-data-requirements","title":"Input Data Requirements","text":""},{"location":"alignment/#supported-data-formats","title":"Supported Data Formats","text":"<p>SMINT's alignment module supports the following data formats: - CSV files (preferred) - Simple tabular format with spatial coordinates - AnnData objects - Python objects with spatial omics data - Pandas DataFrames - In-memory tabular data - 10X Visium data - Spatial transcriptomics from 10X Genomics</p>"},{"location":"alignment/#required-data-columns","title":"Required Data Columns","text":"<p>For optimal alignment, input data files should contain: - Spatial coordinates: Columns named 'x' and 'y' or similar ('X_position', 'Y_position') - Feature values: Gene expression or other features (optional, for feature-based alignment) - Cell/spot IDs: Unique identifiers for each point (optional, but recommended)</p>"},{"location":"alignment/#example-input-data","title":"Example Input Data","text":"<p>Reference data (<code>reference_data.csv</code>): <pre><code>spot_id,x,y,feature1,feature2\n1,100.5,200.3,0.8,0.2\n2,150.2,220.1,0.6,0.4\n...\n</code></pre></p> <p>Target data (<code>target_data.csv</code>): <pre><code>cell_id,x_position,y_position,marker1,marker2\ncell_1,1050.5,2200.3,0.9,0.1\ncell_2,1150.2,2220.1,0.7,0.3\n...\n</code></pre></p>"},{"location":"alignment/#quick-start","title":"Quick Start","text":""},{"location":"alignment/#basic-alignment","title":"Basic Alignment","text":"<pre><code>python -m scripts.run_alignment \\\n    --reference reference_data.csv \\\n    --target target_data.csv \\\n    --output-dir results/alignment \\\n    --method affine \\\n    --ref-x-col x \\\n    --ref-y-col y \\\n    --target-x-col x_position \\\n    --target-y-col y_position\n</code></pre>"},{"location":"alignment/#feature-based-alignment","title":"Feature-Based Alignment","text":"<p>For alignment based on matching gene/protein expression patterns:</p> <pre><code>python -m scripts.run_alignment \\\n    --reference reference_data.csv \\\n    --target target_data.csv \\\n    --output-dir results/alignment \\\n    --method affine \\\n    --use-features \\\n    --ref-feature-cols feature1,feature2 \\\n    --target-feature-cols marker1,marker2 \\\n    --feature-weight 0.7\n</code></pre>"},{"location":"alignment/#detailed-parameter-guide","title":"Detailed Parameter Guide","text":""},{"location":"alignment/#common-parameters","title":"Common Parameters","text":"Parameter Description Default Recommended Values <code>--reference</code> Path to reference data Required - <code>--target</code> Path to target data Required - <code>--output-dir</code> Directory to save results Required - <code>--method</code> Transformation method \"affine\" \"rigid\", \"similarity\", \"affine\", \"projective\" <code>--ref-x-col</code> X coordinate column in reference \"x\" Any column name <code>--ref-y-col</code> Y coordinate column in reference \"y\" Any column name <code>--target-x-col</code> X coordinate column in target \"x\" Any column name <code>--target-y-col</code> Y coordinate column in target \"y\" Any column name <code>--visualize</code> Generate visualizations False -"},{"location":"alignment/#advanced-parameters","title":"Advanced Parameters","text":"Parameter Description Default Notes <code>--use-features</code> Use features for alignment False Enables feature-based alignment <code>--ref-feature-cols</code> Feature columns in reference None Comma-separated column names <code>--target-feature-cols</code> Feature columns in target None Comma-separated column names <code>--feature-weight</code> Weight of features vs. spatial 0.5 0.0-1.0 (higher = more feature influence) <code>--max-points</code> Maximum points to use 10000 Lower for faster processing <code>--ransac-threshold</code> RANSAC inlier threshold 10.0 Lower for stricter matching <code>--ransac-iterations</code> RANSAC iterations 1000 Higher for better robustness <code>--ransac-min-samples</code> Min. samples for RANSAC Method-dependent 2 (rigid), 3 (affine), 4 (projective) <code>--scale-factor</code> Scale factor for coordinates 1.0 Adjusts for different coordinate systems <code>--pre-align</code> Use simple pre-alignment False Helps with very different starting positions"},{"location":"alignment/#quality-control-parameters","title":"Quality Control Parameters","text":"Parameter Description Default Notes <code>--validate</code> Validate alignment quality False Enables quality assessment <code>--holdout-fraction</code> Fraction of points to hold out 0.1 0.05-0.2 recommended <code>--min-confidence</code> Minimum alignment confidence 0.5 0-1 range, higher = stricter <code>--distance-threshold</code> Max allowed point distance 50.0 Units same as coordinates <code>--save-validation-plots</code> Save validation plots False Requires matplotlib"},{"location":"alignment/#alignment-api","title":"Alignment API","text":"<p>For programmatic usage within Python scripts:</p> <pre><code>from smint.alignment import run_alignment, transform_coordinates\n\n# Basic usage\nalignment_result = run_alignment(\n    source_data=\"path/to/target_data.csv\",\n    target_data=\"path/to/reference_data.csv\",\n    method=\"affine\",\n    config={\n        \"source_x_column\": \"x_position\",\n        \"source_y_column\": \"y_position\",\n        \"target_x_column\": \"x\",\n        \"target_y_column\": \"y\",\n        \"ransac_threshold\": 10.0,\n        \"ransac_max_iterations\": 1000\n    }\n)\n\n# Access the transformation matrix\ntransform_matrix = alignment_result[\"transformation_matrix\"]\nquality_metrics = alignment_result[\"quality_metrics\"]\n\n# Apply transformation to coordinates\nimport pandas as pd\ndata_to_transform = pd.read_csv(\"path/to/additional_data.csv\")\ntransformed_coords = transform_coordinates(\n    coordinates=data_to_transform[[\"x_position\", \"y_position\"]].values,\n    transformation_matrix=transform_matrix\n)\n\n# Save transformed coordinates\ndata_to_transform[\"x_transformed\"] = transformed_coords[:, 0]\ndata_to_transform[\"y_transformed\"] = transformed_coords[:, 1]\ndata_to_transform.to_csv(\"path/to/transformed_data.csv\", index=False)\n</code></pre>"},{"location":"alignment/#advanced-feature-based-alignment","title":"Advanced Feature-Based Alignment","text":"<p>SMINT supports alignment based on matching gene/protein expression patterns:</p> <pre><code>from smint.alignment import run_alignment\nimport pandas as pd\n\n# Load data\nreference_data = pd.read_csv(\"reference_data.csv\")\ntarget_data = pd.read_csv(\"target_data.csv\")\n\n# Run feature-based alignment\nalignment_result = run_alignment(\n    source_data=target_data,\n    target_data=reference_data,\n    method=\"affine\",\n    config={\n        \"source_x_column\": \"x_position\",\n        \"source_y_column\": \"y_position\",\n        \"target_x_column\": \"x\",\n        \"target_y_column\": \"y\",\n        \"use_features\": True,\n        \"source_feature_columns\": [\"marker1\", \"marker2\", \"marker3\"],\n        \"target_feature_columns\": [\"feature1\", \"feature2\", \"feature3\"],\n        \"feature_weight\": 0.7,  # 70% features, 30% spatial\n        \"normalize_features\": True\n    }\n)\n</code></pre>"},{"location":"alignment/#transformation-methods-explained","title":"Transformation Methods Explained","text":"<p>SMINT provides several transformation methods with different properties:</p> Method Degrees of Freedom Preserves Use Case Rigid 3 Distances, Angles Same-scale data with rotation/translation Similarity 4 Angles, Relative distances Similar data with uniform scaling Affine 6 Parallel lines Different imaging modalities, tissue deformation Projective 8 Straight lines Significant perspective changes, severe distortion"},{"location":"alignment/#output-files-and-formats","title":"Output Files and Formats","text":"<p>SMINT generates the following output files:</p> File Description Format <code>transformation_matrix.csv</code> Transformation matrix CSV (3\u00d73 matrix) <code>transformed_coordinates.csv</code> Transformed target coordinates CSV with original + transformed coordinates <code>alignment_metrics.json</code> Quality metrics JSON <code>alignment_report.html</code> Interactive visualization HTML (if <code>--visualize</code> is used) <code>validation_plots/*.png</code> Validation visualizations PNG (if validation enabled)"},{"location":"alignment/#visualizing-alignment-results","title":"Visualizing Alignment Results","text":"<p>SMINT provides built-in visualization tools for alignment results:</p> <pre><code>from smint.visualization import visualize_alignment\n\n# Generate interactive visualization\nvisualize_alignment(\n    reference_data=\"path/to/reference_data.csv\",\n    target_data=\"path/to/target_data.csv\",\n    transformed_data=\"path/to/transformed_coordinates.csv\",\n    output_html=\"alignment_visualization.html\",\n    reference_name=\"Spatial Transcriptomics\",\n    target_name=\"IF Imaging\",\n    point_size=5,\n    opacity=0.7,\n    colormap=\"viridis\"\n)\n</code></pre>"},{"location":"alignment/#common-issues-and-troubleshooting","title":"Common Issues and Troubleshooting","text":""},{"location":"alignment/#poor-alignment-quality","title":"Poor Alignment Quality","text":"<ul> <li>Problem: Points not properly aligned</li> <li>Solution: Try different transformation methods (start with affine), adjust RANSAC parameters, use feature-based alignment if possible</li> </ul>"},{"location":"alignment/#flipped-or-rotated-alignment","title":"Flipped or Rotated Alignment","text":"<ul> <li>Problem: Alignment appears mirror-flipped or severely rotated</li> <li>Solution: Use <code>--pre-align</code> option, or manually flip one dataset before alignment</li> </ul>"},{"location":"alignment/#slow-processing","title":"Slow Processing","text":"<ul> <li>Problem: Alignment taking too long</li> <li>Solution: Reduce number of points with <code>--max-points</code>, decrease RANSAC iterations, use simpler transformation method</li> </ul>"},{"location":"alignment/#feature-mismatch","title":"Feature Mismatch","text":"<ul> <li>Problem: Feature-based alignment fails to converge</li> <li>Solution: Verify matching features between datasets, adjust feature weights, normalize features</li> </ul>"},{"location":"alignment/#performance-considerations","title":"Performance Considerations","text":"<p>Alignment performance depends on several factors:</p> <ul> <li>Data size: Larger datasets (&gt;10,000 points) require more processing time</li> <li>Transformation complexity: Projective &gt; Affine &gt; Similarity &gt; Rigid (in terms of computation)</li> <li>Feature-based alignment: Using features increases computation time but may improve accuracy</li> <li>RANSAC parameters: Higher iterations and lower thresholds increase computation time</li> </ul>"},{"location":"alignment/#tips-for-best-results","title":"Tips for Best Results","text":"<ol> <li>Start Simple: Begin with simpler transformations (rigid, similarity) before trying affine or projective</li> <li>Preprocessing: Remove outliers and normalize coordinates before alignment</li> <li>Use Features: When available, feature-based alignment often provides better results</li> <li>Validation: Always validate alignment quality with holdout points</li> <li>Visualization: Visually inspect alignment results to catch issues metrics might miss</li> <li>Iterative Approach: For difficult cases, try iterative alignment with progressively more complex transformations</li> <li>Common Markers: For multi-modal data, focus on features/markers present in both datasets</li> </ol>"},{"location":"alignment/#xenium-to-metabolomics-alignment","title":"Xenium to Metabolomics Alignment","text":""},{"location":"alignment/#overview","title":"Overview","text":"<p>Aligning 10X Xenium spatial transcriptomics data with spatial metabolomics data presents unique challenges: - Different resolution and sampling density - Different coordinate systems and scaling - Potential tissue deformation between modalities - Different feature types (genes vs. metabolites)</p> <p>SMINT provides a specialized module that leverages STalign's Large Deformation Diffeomorphic Metric Mapping (LDDMM) to perform this alignment.</p>"},{"location":"alignment/#quick-start_1","title":"Quick Start","text":"<pre><code>from smint.alignment import align_xenium_to_metabolomics\n\n# Basic usage\naligned_data = align_xenium_to_metabolomics(\n    xenium_file=\"path/to/xenium_data.csv\",\n    metabolomics_file=\"path/to/metabolomics_data.csv\",\n    output_dir=\"alignment_results\",\n    pixel_size=30,\n    visualize=True\n)\n</code></pre>"},{"location":"alignment/#advanced-usage","title":"Advanced Usage","text":"<p>For more complex alignment tasks, you can customize the parameters:</p> <pre><code>from smint.alignment import align_xenium_to_metabolomics\n\n# Advanced usage with custom parameters\naligned_data = align_xenium_to_metabolomics(\n    xenium_file=\"path/to/xenium_data.csv\",\n    metabolomics_file=\"path/to/metabolomics_data.csv\",\n    output_dir=\"alignment_results\",\n    pixel_size=30,\n    xenium_x_col=\"x_centroid\",\n    xenium_y_col=\"y_centroid\",\n    met_x_col=\"x\",\n    met_y_col=\"y\",\n    lddmm_params={\n        'niter': 1500,        # More iterations for difficult alignments\n        'sigmaM': 0.3,        # Smaller kernel for more local deformations\n        'sigmaB': 1.0,        # Control smoothness of backward map\n        'sigmaA': 1.0,        # Control smoothness of forward map\n        'epV': 600,           # Regularization parameter\n        'diffeo_start': 30    # Start diffeomorphic transformation earlier\n    },\n    visualize=True,\n    save_intermediate=True    # Save intermediate results for debugging\n)\n</code></pre>"},{"location":"alignment/#optimizing-alignment-quality","title":"Optimizing Alignment Quality","text":"<p>The alignment quality depends on several factors:</p> <ol> <li>Pixel Size for Rasterization: </li> <li>Typically 20-50\u00b5m works well for Xenium data</li> <li>Too small: Results in sparse representation</li> <li>Too large: Loses spatial resolution</li> <li> <p>Start with 30\u00b5m and adjust based on results</p> </li> <li> <p>LDDMM Parameters:</p> </li> <li><code>sigmaM</code>: Controls local deformation flexibility (smaller = more flexible)</li> <li><code>sigmaB/sigmaA</code>: Controls transformation smoothness</li> <li><code>epV</code>: Regularization strength (higher = smoother but less accurate)</li> <li> <p><code>niter</code>: Number of iterations (higher = potentially better but slower)</p> </li> <li> <p>Pre-processing:</p> </li> <li>Ensure coordinates are in the same scale</li> <li>Remove outlier points that could distort alignment</li> <li>For very different orientations, consider manual pre-alignment</li> </ol> <p>For detailed guidance on alignment optimization, see the full Xenium-Metabolomics alignment documentation.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>SMINT uses YAML configuration files to control various aspects of the processing pipeline. This page explains how to configure SMINT for your specific needs.</p>"},{"location":"configuration/#configuration-file-structure","title":"Configuration File Structure","text":"<p>SMINT configuration files are written in YAML format and have the following structure:</p> <p>```yaml</p>"},{"location":"configuration/#base-configuration","title":"Base configuration","text":"<p>output_dir: \"results/segmentation\" tile_info_path: \"results/segmentation/current_tile_info.txt\" live_update_image_path: \"results/segmentation/live_view.png\"</p>"},{"location":"configuration/#distributed-processing","title":"Distributed processing","text":"<p>use_gpu: true n_workers: null  # null = use all available workers chunk_size: [2048, 2048] memory_limit: \"16GB\"</p>"},{"location":"configuration/#model-paths","title":"Model paths","text":"<p>model_paths:   - \"cyto\"  # Built-in Cellpose model for cytoplasm   - \"nuclei\"  # Built-in Cellpose model for nuclei   # - \"/path/to/custom/model\"  # Path to a custom model</p>"},{"location":"configuration/#cell-segmentation-parameters","title":"Cell segmentation parameters","text":"<p>cell_model_params:   diameter: 120.0   flow_threshold: 0.4   cellprob_threshold: -1.5   channels: [1, 2]  # [cytoplasm, nucleus]</p>"},{"location":"configuration/#nuclear-segmentation-parameters","title":"Nuclear segmentation parameters","text":"<p>nuclei_model_params:   diameter: 40.0   flow_threshold: 0.4   cellprob_threshold: -1.2   channels: [2, 0]  # [nucleus, no second channel]</p>"},{"location":"configuration/#adaptive-nuclear-segmentation","title":"Adaptive nuclear segmentation","text":"<p>adaptive_nuclei:   enable: false   cellprob_lower_limit: -6.0   step_decrement: 0.2   max_attempts: 3   trigger_ratio: 0.05</p>"},{"location":"configuration/#preprocessing-options","title":"Preprocessing options","text":"<p>preprocessing:   sigma: 1.0  # Gaussian blur sigma   normalize: true   channel_names:     - \"DAPI\"     - \"AF568\"     - \"AF647\"</p>"},{"location":"configuration/#visualization-options","title":"Visualization options","text":"<p>visualization:   enable: true   output_dir: \"results/segmentation/visualizations\"   num_chunks_to_visualize: 5   roi_size: [2024, 2024]   background_channel_indices: [0, 1]  # Channels to use for visualization background</p>"},{"location":"dependency_handling/","title":"Dependency Handling","text":"<p>SMINT is designed with graceful dependency handling to ensure robust operation across different environments, even when some optional dependencies are missing.</p>"},{"location":"dependency_handling/#design-philosophy","title":"Design Philosophy","text":"<p>The core design principles for dependency handling in SMINT are:</p> <ol> <li>Graceful Degradation: The package should continue to function with reduced capabilities when optional dependencies are missing.</li> <li>Clear Feedback: Users should receive informative messages about missing dependencies and their impact.</li> <li>Minimal Core Requirements: The essential functionality should work with a minimal set of dependencies.</li> <li>Easy Extension: Adding optional dependencies should enable additional features without code changes.</li> </ol>"},{"location":"dependency_handling/#how-dependency-handling-works","title":"How Dependency Handling Works","text":""},{"location":"dependency_handling/#detection-mechanism","title":"Detection Mechanism","text":"<p>SMINT uses a consistent pattern across all modules to detect and handle optional dependencies:</p> <pre><code># Check for optional dependency\ntry:\n    import some_package\n    SOME_PACKAGE_AVAILABLE = True\nexcept ImportError:\n    SOME_PACKAGE_AVAILABLE = False\n    logging.warning(\"some_package not available. Some functionality will be limited.\")\n</code></pre>"},{"location":"dependency_handling/#implementation-pattern","title":"Implementation Pattern","text":"<p>Functions that require optional dependencies check their availability before execution:</p> <pre><code>def function_requiring_dependency():\n    if not SOME_PACKAGE_AVAILABLE:\n        logging.error(\"This function requires some_package to be installed.\")\n        return {\"error\": \"Missing required dependency: some_package\"}\n\n    # Normal function implementation\n    ...\n</code></pre>"},{"location":"dependency_handling/#module-specific-dependencies","title":"Module-Specific Dependencies","text":""},{"location":"dependency_handling/#segmentation-module","title":"Segmentation Module","text":"Dependency Required For Fallback Behavior cellpose Cell segmentation models Error message with installation instructions opencv-python Image I/O and contour extraction Limited visualization, no mask saving/loading dask[distributed] Distributed processing Single-process implementation only dask-cuda GPU acceleration CPU-only implementation"},{"location":"dependency_handling/#visualization-module","title":"Visualization Module","text":"Dependency Required For Fallback Behavior matplotlib All plotting functionality Error message with installation instructions opencv-python Image I/O and processing Limited visualization capabilities tkinter Live Scan Viewer GUI Command-line only interface"},{"location":"dependency_handling/#r-integration-module","title":"R Integration Module","text":"Dependency Required For Fallback Behavior rpy2 Direct R integration Fallback to subprocess R script execution pandas Data transfer between Python and R Required dependency R (system) All R functionality Error message with installation instructions"},{"location":"dependency_handling/#checking-dependency-status","title":"Checking Dependency Status","text":"<p>You can check the status of optional dependencies programmatically:</p> <pre><code>import importlib\n\ndef check_dependency(package_name):\n    try:\n        importlib.import_module(package_name)\n        return True\n    except ImportError:\n        return False\n\n# Check for cellpose\ncellpose_available = check_dependency(\"cellpose\")\nprint(f\"Cellpose available: {cellpose_available}\")\n\n# Check for opencv\nopencv_available = check_dependency(\"cv2\")\nprint(f\"OpenCV available: {opencv_available}\")\n\n# Check for rpy2\nrpy2_available = check_dependency(\"rpy2\")\nprint(f\"rpy2 available: {rpy2_available}\")\n</code></pre>"},{"location":"dependency_handling/#warnings-and-error-messages","title":"Warnings and Error Messages","text":"<p>SMINT provides detailed warnings and error messages when dependencies are missing:</p> <ol> <li>Import-time warnings: When SMINT is imported, it will log warnings about missing optional dependencies.</li> <li>Function-specific errors: Functions that require missing dependencies will provide clear error messages.</li> <li>Installation instructions: Error messages include instructions for installing missing dependencies.</li> </ol>"},{"location":"dependency_handling/#customizing-error-handling","title":"Customizing Error Handling","text":"<p>You can customize the behavior when dependencies are missing by modifying the logging configuration:</p> <pre><code>import logging\n\n# Set logging level to ERROR to suppress warnings about missing dependencies\nlogging.basicConfig(level=logging.ERROR)\n\n# Or capture logs to a file\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='smint.log'\n)\n</code></pre>"},{"location":"dependency_handling/#best-practices-for-dependency-management","title":"Best Practices for Dependency Management","text":"<ol> <li> <p>Install only what you need: Use selective installation to minimize dependencies:    <pre><code>pip install \"smint[segmentation]\"  # Only install segmentation dependencies\n</code></pre></p> </li> <li> <p>Check availability before calling functions:    <pre><code>import smint\nfrom smint.segmentation import run_distributed_segmentation\n\n# Check if distributed processing is available\ntry:\n   import distributed\n   distributed_available = True\nexcept ImportError:\n   distributed_available = False\n\n# Use appropriate function based on availability\nif distributed_available:\n   result = run_distributed_segmentation(...)\nelse:\n   result = smint.segmentation.process_large_image(...)\n</code></pre></p> </li> <li> <p>Provide feedback to users: When building applications on top of SMINT, forward dependency warnings to users.</p> </li> </ol>"},{"location":"examples/","title":"Examples","text":"<p>This page provides complete examples of SMINT workflows, demonstrating how to use the package for different spatial omics applications.</p>"},{"location":"examples/#basic-workflow","title":"Basic Workflow","text":"<p>The following example demonstrates a complete workflow from preprocessing through segmentation to visualization:</p> <p>```python import os from smint.preprocessing import preprocess_ome_tiff from smint.segmentation import process_large_image from smint.visualization import visualize_cell_outlines import pandas as pd import matplotlib.pyplot as plt</p>"},{"location":"examples/#set-up-directories","title":"Set up directories","text":"<p>image_path = \"path/to/image.ome.tif\" output_dir = \"results\" os.makedirs(output_dir, exist_ok=True)</p>"},{"location":"examples/#step-1-preprocess-the-image","title":"Step 1: Preprocess the image","text":"<p>preprocessed = preprocess_ome_tiff(     image_path=image_path,     sigma=1.5,     normalize=True )</p>"},{"location":"examples/#combine-channels-if-needed","title":"Combine channels if needed","text":"<p>if len(preprocessed) &gt;= 2:     from smint.preprocessing import combine_channels</p> <pre><code>channel_names = list(preprocessed.keys())\ncombined = combine_channels(\n    preprocessed[channel_names[0]],\n    preprocessed[channel_names[1]]\n)\n\n# Save combined image\nimport tifffile\ncombined_path = os.path.join(output_dir, \"combined.tif\")\ntifffile.imwrite(combined_path, combined)\nprint(f\"Saved combined image to {combined_path}\")\n\n# Use combined image for segmentation\nsegmentation_input = combined_path\n</code></pre> <p>else:     # Use first channel for segmentation     import tifffile     channel_name = list(preprocessed.keys())[0]     segmentation_input = os.path.join(output_dir, f\"{channel_name}.tif\")     tifffile.imwrite(segmentation_input, preprocessed[channel_name])</p>"},{"location":"examples/#step-2-segment-cells-and-nuclei","title":"Step 2: Segment cells and nuclei","text":"<p>results = process_large_image(     image_path=segmentation_input,     csv_base_path=os.path.join(output_dir, \"cell_outlines\"),     chunk_size=(2048, 2048),     # Cell Model parameters     cell_model_path=\"cyto\",     cells_diameter=120.0,     cells_flow_threshold=0.4,     cells_cellprob_threshold=-1.5,     cells_channels=[0, 0],     # Nuclei Model parameters     nuclei_model_path=\"nuclei\",     nuclei_diameter=40.0,     nuclei_flow_threshold=0.4,     nuclei_cellprob_threshold=-1.2,     nuclei_channels=[0, 0],     # Visualization parameters     visualize=True,     visualize_output_dir=os.path.join(output_dir, \"visualizations\") )</p> <p>print(f\"Found {results['total_cells']} cells and {results['total_nuclei']} nuclei\")</p>"},{"location":"examples/#step-3-load-and-visualize-the-results","title":"Step 3: Load and visualize the results","text":"<p>if results.get('cells_csv_path'):     cells_df = pd.read_csv(results['cells_csv_path'])     print(f\"Loaded {cells_df['global_cell_id'].nunique()} cells\")</p> <pre><code># Create visualization\nfig = visualize_cell_outlines(cells_df, color_by='global_cell_id')\nplt.savefig(os.path.join(output_dir, \"cell_outlines.png\"), dpi=300)\nplt.close(fig)\n</code></pre>"},{"location":"hpc_deployment/","title":"HPC Deployment","text":"<p>SMINT is designed to run efficiently on High-Performance Computing (HPC) clusters, taking advantage of multiple CPUs and GPUs for processing large spatial omics datasets. This page explains how to deploy SMINT on SLURM-based HPC systems.</p>"},{"location":"hpc_deployment/#overview","title":"Overview","text":"<p>Running SMINT on an HPC cluster involves the following steps:</p> <ol> <li>Install SMINT on the HPC system</li> <li>Prepare your configuration file</li> <li>Submit jobs using SLURM submission scripts</li> <li>Monitor job progress</li> <li>Collect and analyze results</li> </ol>"},{"location":"hpc_deployment/#installation-on-hpc","title":"Installation on HPC","text":""},{"location":"hpc_deployment/#using-environment-modules","title":"Using Environment Modules","text":"<p>Most HPC systems use environment modules. Load the required modules and install SMINT:</p> <p>```bash</p>"},{"location":"hpc_deployment/#load-required-modules","title":"Load required modules","text":"<p>module load python/3.8 module load cuda/11.3 module load miniconda3</p>"},{"location":"hpc_deployment/#create-a-conda-environment","title":"Create a conda environment","text":"<p>conda create -n smint python=3.8 conda activate smint</p>"},{"location":"hpc_deployment/#install-smint","title":"Install SMINT","text":"<p>pip install smint</p>"},{"location":"installation/","title":"Installation","text":"<p>This guide covers the installation of SMINT and its dependencies.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>SMINT requires the following:</p> <ul> <li>Python 3.8 or higher</li> <li>CUDA toolkit (for GPU support, optional)</li> <li>R 4.0 or higher (for R integration, optional)</li> </ul>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Memory: At least 16GB RAM, 32GB+ recommended for large images</li> <li>CPU: Multi-core processor (8+ cores recommended)</li> <li>GPU: NVIDIA GPU with at least 8GB VRAM (for GPU-accelerated segmentation, optional)</li> <li>Storage: Depends on your image sizes, but typically 100GB+ free space</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#option-1-install-from-pypi-recommended","title":"Option 1: Install from PyPI (Recommended)","text":"<p>The simplest way to install SMINT is using pip:</p> <pre><code>pip install smint\n</code></pre>"},{"location":"installation/#option-2-install-from-source","title":"Option 2: Install from Source","text":"<p>For the latest development version or to contribute to the project:</p> <pre><code>git clone https://github.com/JurgenKriel/SMINT.git\ncd SMINT\npip install -e .\n</code></pre>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>SMINT is designed with a modular approach to dependencies. Core functionality will work with minimal dependencies, while optional features require additional packages.</p>"},{"location":"installation/#core-dependencies-automatically-installed","title":"Core Dependencies (Automatically Installed)","text":"<p>These dependencies are automatically installed when you install SMINT:</p> <ul> <li>numpy: For numerical operations</li> <li>pandas: For data manipulation</li> <li>matplotlib: For visualization</li> <li>dask: For parallel computing (base package)</li> <li>scikit-image: For image processing</li> <li>tifffile: For reading/writing OME-TIFF files</li> </ul>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>These dependencies enable additional features but are not required for core functionality:</p>"},{"location":"installation/#cell-segmentation","title":"Cell Segmentation","text":"<ul> <li> <p>cellpose: For cell segmentation models   <pre><code>pip install cellpose\n</code></pre></p> </li> <li> <p>opencv-python: For image processing and contour extraction   <pre><code>pip install opencv-python\n</code></pre></p> </li> </ul>"},{"location":"installation/#distributed-processing","title":"Distributed Processing","text":"<ul> <li> <p>dask[distributed]: For distributed computing   <pre><code>pip install \"dask[distributed]\"\n</code></pre></p> </li> <li> <p>dask-cuda: For GPU-accelerated distributed computing (requires CUDA)   <pre><code>pip install dask-cuda\n</code></pre></p> </li> </ul>"},{"location":"installation/#r-integration","title":"R Integration","text":"<ul> <li>rpy2: For direct R integration   <pre><code>pip install rpy2\n</code></pre></li> </ul>"},{"location":"installation/#installation-with-all-optional-dependencies","title":"Installation with All Optional Dependencies","text":"<p>To install SMINT with all optional dependencies:</p> <pre><code>pip install \"smint[all]\"\n</code></pre> <p>Or selectively:</p> <pre><code>pip install \"smint[segmentation]\"  # For cell segmentation features\npip install \"smint[distributed]\"   # For distributed computing features\npip install \"smint[r]\"             # For R integration features\n</code></pre>"},{"location":"installation/#graceful-dependency-handling","title":"Graceful Dependency Handling","text":"<p>SMINT is designed to degrade gracefully when optional dependencies are missing:</p> <ol> <li>Missing a dependency? SMINT will log a warning but continue to operate with limited functionality.</li> <li>Function that requires a missing dependency? You'll get a clear error message explaining which package you need to install.</li> <li>Want to check available functionality? Run the following code:</li> </ol> <pre><code>import smint\nprint(f\"SMINT package version: {smint.__version__}\")\nprint(\"Available modules:\")\n[print(f\"- {module}\") for module in smint.__all__]\n</code></pre> <p>You can also check specific dependency availability:</p> <pre><code># Check cellpose availability\ntry:\n    import cellpose\n    print(\"Cellpose is available\")\nexcept ImportError:\n    print(\"Cellpose is not available\")\n</code></pre>"},{"location":"r_integration/","title":"R Integration","text":"<p>SMINT provides seamless integration with R for spatial omics data analysis, allowing you to leverage existing R packages within your Python workflow.</p>"},{"location":"r_integration/#quick-start","title":"Quick Start","text":""},{"location":"r_integration/#running-an-r-script","title":"Running an R Script","text":"<p>```python from smint.r_integration import run_r_script</p>"},{"location":"r_integration/#run-an-r-script-with-arguments","title":"Run an R script with arguments","text":"<p>return_code = run_r_script(     script_path=\"path/to/analysis.R\",     args=[\"--input\", \"data.csv\", \"--output\", \"results/\"] )</p> <p>print(f\"Script completed with return code: {return_code}\")</p>"},{"location":"segmentation/","title":"Cell Segmentation","text":"<p>SMINT provides powerful tools for segmenting cells and nuclei in whole-slide images, with support for distributed processing and multiple GPUs. This comprehensive guide covers all aspects of the segmentation pipeline, from data preparation to post-processing.</p>"},{"location":"segmentation/#overview-of-segmentation-pipeline","title":"Overview of Segmentation Pipeline","text":"<p>The SMINT segmentation pipeline consists of several key stages:</p> <ol> <li>Image Preprocessing - Preparing and normalizing input images</li> <li>Cell Segmentation - Identifying whole cells using Cellpose</li> <li>Nuclei Segmentation - Identifying cell nuclei (optional)</li> <li>Post-processing - Refining segmentation results and extracting features</li> <li>Visualization - Generating visual outputs for quality control</li> </ol>"},{"location":"segmentation/#input-data-requirements","title":"Input Data Requirements","text":""},{"location":"segmentation/#supported-image-formats","title":"Supported Image Formats","text":"<p>SMINT supports the following image formats: - OME-TIFF (preferred) - Multi-channel, multi-resolution format with metadata - TIFF - Standard format, single or multi-channel - CZI - Carl Zeiss format, requires additional processing</p>"},{"location":"segmentation/#required-image-properties","title":"Required Image Properties","text":"<p>For optimal segmentation results, input images should have: - Resolution: Ideally 0.5-1 \u03bcm/pixel for cell segmentation, 0.25-0.5 \u03bcm/pixel for nuclei - Channels:    - At least one membrane/cytoplasm channel (e.g., WGA, phalloidin)   - At least one nuclear channel (e.g., DAPI, Hoechst) for nuclei segmentation - Bit depth: 8-bit or 16-bit grayscale per channel - Quality: Minimal noise, good contrast between cells and background</p>"},{"location":"segmentation/#quick-start","title":"Quick Start","text":""},{"location":"segmentation/#single-process-segmentation","title":"Single-Process Segmentation","text":"<p>For standard whole-slide images that fit in memory:</p> <pre><code>python -m scripts.run_segmentation \\\n    --image path/to/image.ome.tiff \\\n    --output-dir results/segmentation \\\n    --cell-channel 0 \\\n    --nuclei-channel 1 \\\n    --cell-diameter 60 \\\n    --nuclei-diameter 30 \\\n    --visualize\n</code></pre>"},{"location":"segmentation/#multi-gpu-distributed-segmentation","title":"Multi-GPU Distributed Segmentation","text":"<p>For very large images requiring multiple GPUs:</p> <pre><code>python -m scripts.run_distributed_segmentation \\\n    --image path/to/large_image.ome.tiff \\\n    --output-dir results/segmentation \\\n    --cell-channel 0 \\\n    --nuclei-channel 1 \\\n    --cell-diameter 60 \\\n    --nuclei-diameter 30 \\\n    --chunk-size 2048 2048 \\\n    --gpus 0 1 2 3 \\\n    --visualize\n</code></pre>"},{"location":"segmentation/#detailed-parameter-guide","title":"Detailed Parameter Guide","text":""},{"location":"segmentation/#common-parameters","title":"Common Parameters","text":"Parameter Description Default Recommended Range <code>--image</code> Path to input image Required - <code>--output-dir</code> Directory to save results Required - <code>--cell-channel</code> Channel index for cell segmentation 0 Depends on staining <code>--nuclei-channel</code> Channel index for nuclei segmentation 1 Depends on staining <code>--cell-diameter</code> Expected cell diameter in pixels 80 40-120 <code>--nuclei-diameter</code> Expected nuclei diameter in pixels 40 20-60 <code>--flow-threshold</code> Flow threshold for Cellpose 0.4 0.2-0.8 <code>--cellprob-threshold</code> Cell probability threshold -1.0 -3.0-0.0 <code>--visualize</code> Generate visualizations False - <code>--chunk-size</code> Size of image chunks to process 2048 2048 Depends on GPU memory"},{"location":"segmentation/#advanced-parameters","title":"Advanced Parameters","text":"Parameter Description Default Notes <code>--pretrained-model</code> Path to custom Cellpose model None Use for specialized cell types <code>--model-type</code> Cellpose model type \"cyto\" Options: \"cyto\", \"nuclei\", \"cyto2\", or custom path <code>--min-cell-size</code> Minimum cell size in pixels 15 Filters out small objects <code>--omit-overlap</code> Remove overlapping cell masks False Useful for densely packed cells <code>--adaptive-threshold</code> Use adaptive thresholding False Helps with variable image intensity <code>--normalize-channels</code> Normalize channel intensities True Improves segmentation quality <code>--save-zarr</code> Save results in Zarr format False Useful for very large datasets <code>--no-nuclei</code> Skip nuclei segmentation False Speeds up processing"},{"location":"segmentation/#distributed-processing-parameters","title":"Distributed Processing Parameters","text":"Parameter Description Default Notes <code>--gpus</code> GPU device IDs to use None Space-separated list of GPU IDs <code>--workers-per-gpu</code> Dask workers per GPU 1 Increase for CPU-bound tasks <code>--memory-limit</code> Memory limit per worker \"10GB\" Adjust based on available RAM <code>--scheduler-address</code> Dask scheduler address None For connecting to existing cluster <code>--overlap</code> Overlap between chunks 64 Prevents boundary artifacts <code>--batch-size</code> Number of chunks per batch 4 Adjust based on GPU memory"},{"location":"segmentation/#segmentation-api","title":"Segmentation API","text":"<p>For programmatic usage within Python scripts:</p> <pre><code>from smint.segmentation import process_large_image\n\n# Basic usage\nresults = process_large_image(\n    image_path=\"path/to/image.ome.tiff\",\n    csv_base_path=\"results/segmentation\",\n    chunk_size=(2048, 2048),\n    # Cell parameters\n    cell_model_path=\"cyto\",\n    cells_diameter=80.0,\n    cells_flow_threshold=0.4,\n    cells_cellprob_threshold=-1.5,\n    cells_channels=[0, 0],  # [channel, 0] for grayscale, [channel1, channel2] for RGB\n    # Nuclei parameters\n    nuclei_model_path=\"nuclei\",\n    nuclei_diameter=40.0,\n    nuclei_flow_threshold=0.4,\n    nuclei_cellprob_threshold=-1.5,\n    nuclei_channels=[1, 0],  # [channel, 0] for grayscale\n    # Visualization\n    visualize=True,\n    visualize_output_dir=\"results/visualization\",\n    num_visualize_chunks=5,\n    visualize_roi_size=(512, 512)\n)\n\n# Access the results\ncell_outlines = results[\"cell_outlines\"]\nnuclei_outlines = results[\"nuclei_outlines\"]\n</code></pre> <p>For distributed processing:</p> <pre><code>from smint.segmentation.distributed_seg import process_large_image_distributed\n\n# Basic distributed usage\nresults = process_large_image_distributed(\n    image_path=\"path/to/large_image.ome.tiff\",\n    output_zarr_path=\"results/segmentation.zarr\",\n    csv_path=\"results/segmentation.csv\",\n    blocksize=(2048, 2048),\n    channel=0,  # Main channel for segmentation\n    gpus=[0, 1, 2, 3],  # List of GPU IDs\n    overlap=64,  # Overlap between chunks\n    batch_size=4,  # Number of chunks per batch\n    model_type=\"cyto\",  # Cellpose model type\n    diameter=80.0,  # Expected cell diameter\n    flow_threshold=0.4,\n    cellprob_threshold=-1.5\n)\n</code></pre>"},{"location":"segmentation/#advanced-adaptive-segmentation","title":"Advanced Adaptive Segmentation","text":"<p>SMINT supports adaptive segmentation that dynamically adjusts parameters based on local image characteristics:</p> <pre><code>from smint.segmentation import process_large_image\n\nresults = process_large_image(\n    # Basic parameters as above, plus:\n    enable_adaptive_nuclei=True,\n    nuclei_adaptive_flow_min=0.1,\n    nuclei_adaptive_flow_step_decrement=0.1,\n    nuclei_max_adaptive_attempts=5,\n    adaptive_nuclei_trigger_ratio=0.05  # Retry if nuclei count &lt; 5% of cells\n)\n</code></pre>"},{"location":"segmentation/#output-files-and-formats","title":"Output Files and Formats","text":"<p>SMINT generates the following output files:</p> File Description Format <code>cells_outlines.csv</code> Cell outline coordinates CSV with columns: <code>cell_id,x,y,chunk_id</code> <code>nuclei_outlines.csv</code> Nuclei outline coordinates CSV with columns: <code>nuclei_id,x,y,chunk_id</code> <code>cell_features.csv</code> Extracted cell features CSV with measurements for each cell <code>segmentation_metadata.json</code> Segmentation parameters and stats JSON <code>visualization/*.png</code> Visualization images PNG <code>chunks/*.npy</code> Raw segmentation masks (if saved) NumPy arrays <code>*.zarr</code> Zarr store (for distributed processing) Zarr directory structure"},{"location":"segmentation/#live-segmentation-viewer","title":"Live Segmentation Viewer","text":"<p>SMINT includes a live segmentation viewer for monitoring the segmentation process in real-time:</p> <pre><code>from smint.visualization.live_scan_viewer import LiveScanViewer\nimport tkinter as tk\n\n# Initialize the viewer\nroot = tk.Tk()\nviewer = LiveScanViewer(\n    master=root,\n    full_scan_path=\"path/to/image.ome.tiff\",\n    segmentation_history_dir=\"results/segmentation\",\n    tile_info_path=\"results/tile_info.json\",\n    update_interval_ms=1000  # Update every 1 second\n)\n\n# Start the viewer\nviewer.pack(fill=tk.BOTH, expand=True)\nroot.mainloop()\n</code></pre>"},{"location":"segmentation/#common-issues-and-troubleshooting","title":"Common Issues and Troubleshooting","text":""},{"location":"segmentation/#poor-segmentation-quality","title":"Poor Segmentation Quality","text":"<ul> <li>Problem: Cells or nuclei not properly detected</li> <li>Solution: Adjust diameter, flow_threshold, and cellprob_threshold. Try using larger diameter for bigger cells, lower flow_threshold for weakly stained cells.</li> </ul>"},{"location":"segmentation/#memory-errors","title":"Memory Errors","text":"<ul> <li>Problem: \"CUDA out of memory\" or other memory-related errors</li> <li>Solution: Reduce chunk_size, increase overlap, or use distributed processing with multiple GPUs.</li> </ul>"},{"location":"segmentation/#processing-speed","title":"Processing Speed","text":"<ul> <li>Problem: Segmentation taking too long</li> <li>Solution: Use multi-GPU processing, reduce visualization, skip nuclei segmentation if not needed.</li> </ul>"},{"location":"segmentation/#boundary-artifacts","title":"Boundary Artifacts","text":"<ul> <li>Problem: Cell masks cut off at chunk boundaries</li> <li>Solution: Increase overlap between chunks or post-process with stitch_masks=True.</li> </ul>"},{"location":"segmentation/#performance-benchmarks","title":"Performance Benchmarks","text":"<p>SMINT segmentation performance on different hardware configurations:</p> Image Size Hardware Processing Time Memory Usage 10k \u00d7 10k Single GPU (RTX 3090) ~5 minutes ~8 GB VRAM 50k \u00d7 50k Single GPU (RTX 3090) ~1 hour ~10 GB VRAM 50k \u00d7 50k 4\u00d7 GPUs (RTX 3090) ~15 minutes ~8 GB VRAM per GPU 100k \u00d7 100k 4\u00d7 GPUs (RTX 3090) ~1 hour ~8 GB VRAM per GPU"},{"location":"segmentation/#tips-for-best-results","title":"Tips for Best Results","text":"<ol> <li>Image Quality: Start with high-quality, well-stained images for best results</li> <li>Parameter Tuning: Optimize cell_diameter, flow_threshold, and cellprob_threshold for your specific images</li> <li>Chunk Size: Balance between processing speed (larger chunks) and memory usage (smaller chunks)</li> <li>Custom Models: Train custom Cellpose models for specialized cell types</li> <li>Channel Selection: Choose channels with strongest cell/nuclei signal for segmentation</li> <li>Validation: Always validate segmentation quality with visualizations</li> <li>Adaptive Approach: Use adaptive parameters for images with varying intensity or cell density</li> </ol>"},{"location":"xenium_metabolomics_alignment/","title":"Aligning Xenium Spatial Transcriptomics with Spatial Metabolomics","text":"<p>This guide provides a detailed walkthrough for aligning 10X Xenium spatial transcriptomics data with spatial metabolomics data using STalign within the SMINT framework.</p>"},{"location":"xenium_metabolomics_alignment/#overview","title":"Overview","text":"<p>Integrating spatial transcriptomics data with spatial metabolomics presents unique challenges due to: - Different resolution and sampling density - Distinct coordinate systems - Potential tissue deformation between acquisitions - Different feature types (genes vs. metabolites)</p> <p>The SMINT package leverages STalign (from the JEFworks Lab) to perform robust alignment using diffeomorphic transformations that can account for non-linear deformations between modalities.</p>"},{"location":"xenium_metabolomics_alignment/#prerequisites","title":"Prerequisites","text":"<p>Before beginning the alignment process, ensure you have:</p> <ul> <li>10X Xenium spatial transcriptomics data processed into a coordinate file</li> <li>Spatial metabolomics data in matrix format with x,y coordinates</li> <li>The STalign package installed (<code>pip install STalign</code>)</li> <li>Sufficient computational resources (GPU recommended for large datasets)</li> </ul>"},{"location":"xenium_metabolomics_alignment/#step-1-data-preparation","title":"Step 1: Data Preparation","text":""},{"location":"xenium_metabolomics_alignment/#spatial-metabolomics-data","title":"Spatial Metabolomics Data","text":"<p>The spatial metabolomics data should be in a CSV format with: - Row indices for unique spot/pixel identifiers - <code>x</code> and <code>y</code> columns for spatial coordinates - Additional columns for m/z values representing metabolite intensities</p> <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef read_sm_matrix(mtx_file, verbose=True):\n    \"\"\"\n    Read a Spatial Metabolomics matrix file and extract coordinates and data\n    \"\"\"\n    if verbose:\n        print(\"Reading matrix file...\")\n\n    try:\n        data = pd.read_csv(mtx_file, index_col=0)\n        numeric_cols = []\n        for col in data.columns:\n            try:\n                numeric_cols.append(float(col))\n            except ValueError:\n                continue\n    except Exception as e:\n        raise Exception(f\"Error reading matrix file: {e}\")\n\n    coordinates = data[['x', 'y']].values\n\n    if verbose:\n        print(f\"Found {len(coordinates)} coordinate pairs\")\n        print(f\"Found {len(numeric_cols)} m/z values\")\n\n    return coordinates, data, numeric_cols\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#xenium-data","title":"Xenium Data","text":"<p>Xenium data should be processed to extract cell centroids:</p> <pre><code>def read_xenium_data(xenium_file, verbose=True):\n    \"\"\"\n    Read 10X Xenium data and extract cell coordinates\n    \"\"\"\n    if verbose:\n        print(\"Reading Xenium cell coordinates...\")\n\n    try:\n        data = pd.read_csv(xenium_file)\n        # Ensure the necessary columns exist\n        required_cols = ['x_centroid', 'y_centroid']\n        for col in required_cols:\n            if col not in data.columns:\n                raise ValueError(f\"Required column '{col}' not found in Xenium data\")\n    except Exception as e:\n        raise Exception(f\"Error reading Xenium file: {e}\")\n\n    coordinates = data[['x_centroid', 'y_centroid']].values\n\n    if verbose:\n        print(f\"Found {len(coordinates)} cell coordinates\")\n\n    return coordinates, data\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#step-2-visualizing-data-before-alignment","title":"Step 2: Visualizing Data Before Alignment","text":"<p>Visualizing both datasets before alignment helps assess the initial misalignment and identify potential challenges:</p> <pre><code>def plot_non_zero_coordinates(coordinates, data, title=\"Coordinates Plot\"):\n    \"\"\"\n    Plot the coordinates of all non-zero m/z ratios for spatial metabolomics\n    or all cell coordinates for Xenium data\n    \"\"\"\n    plt.figure(figsize=(12, 10))\n\n    # For spatial metabolomics data\n    if 'mz_values' in data.columns:\n        mz_values = [float(col) for col in data.columns if col.replace('.', '').isdigit()]\n        for mz in mz_values:\n            column_name = str(mz)\n            intensities = data[column_name].values\n\n            # Filter coordinates where intensity is greater than zero\n            non_zero_indices = np.where(intensities &gt; 0)[0]\n            filtered_coordinates = coordinates[non_zero_indices]\n\n            # Plot non-zero coordinates\n            plt.scatter(filtered_coordinates[:, 0], filtered_coordinates[:, 1], \n                        s=10, alpha=0.5, color='blue')\n    else:\n        # For Xenium data, plot all coordinates\n        plt.scatter(coordinates[:, 0], coordinates[:, 1], \n                    s=10, alpha=0.5, color='red')\n\n    plt.xlabel('X coordinate')\n    plt.ylabel('Y coordinate')\n    plt.title(title)\n    plt.grid(True)\n    plt.xlim(coordinates[:, 0].min() - 1, coordinates[:, 0].max() + 1)\n    plt.ylim(coordinates[:, 1].min() - 1, coordinates[:, 1].max() + 1)\n    plt.savefig(f\"{title.replace(' ', '_')}.png\", dpi=300)\n    plt.show()\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#step-3-rasterization","title":"Step 3: Rasterization","text":"<p>STalign works with rasterized (gridded) data. The rasterization step transforms point clouds into pixel-based representations:</p> <pre><code>import STalign\n\ndef rasterize_coordinates(x_coords, y_coords, pixel_size, verbose=True):\n    \"\"\"\n    Convert point coordinates to a rasterized grid\n\n    Parameters:\n    -----------\n    x_coords : numpy.ndarray\n        X coordinates of the points\n    y_coords : numpy.ndarray\n        Y coordinates of the points\n    pixel_size : float\n        Size of the pixels in the rasterized grid\n    verbose : bool\n        Whether to display the rasterization result\n\n    Returns:\n    --------\n    tuple\n        (X grid, Y grid, intensity values, figure if verbose=True)\n    \"\"\"\n    if verbose:\n        print(f\"Rasterizing {len(x_coords)} points with pixel size {pixel_size}\")\n\n    # Perform rasterization\n    X_grid, Y_grid, intensity, fig = STalign.rasterize(x_coords, y_coords, dx=pixel_size)\n\n    if verbose:\n        print(f\"Rasterized grid shape: {intensity.shape}\")\n        plt.savefig(f\"rasterized_grid_size_{pixel_size}.png\", dpi=300)\n        plt.close(fig)\n\n    return X_grid, Y_grid, intensity, fig if verbose else None\n</code></pre> <p>The pixel size parameter (<code>dx</code>) is critical: - Too small: Sparse representation with many empty pixels - Too large: Loss of spatial resolution and detail - Optimal: Usually determined empirically (start with 20-50\u00b5m for Xenium data)</p>"},{"location":"xenium_metabolomics_alignment/#step-4-running-lddmm-alignment","title":"Step 4: Running LDDMM Alignment","text":"<p>The Large Deformation Diffeomorphic Metric Mapping (LDDMM) algorithm performs the alignment:</p> <pre><code>def run_lddmm_alignment(source_grid, target_grid, source_intensity, target_intensity, params=None):\n    \"\"\"\n    Perform LDDMM alignment between source and target datasets\n\n    Parameters:\n    -----------\n    source_grid : tuple\n        (Y grid, X grid) for source data\n    target_grid : tuple\n        (Y grid, X grid) for target data\n    source_intensity : numpy.ndarray\n        Intensity values for source grid\n    target_intensity : numpy.ndarray\n        Intensity values for target grid\n    params : dict, optional\n        Parameters for LDDMM algorithm\n\n    Returns:\n    --------\n    dict\n        LDDMM output containing transformation parameters\n    \"\"\"\n    # Default parameters if none provided\n    if params is None:\n        params = {\n            'niter': 1000,  # Maximum iterations\n            'diffeo_start': 50,  # Start diffeomorphic transformation earlier\n            'sigmaM': 0.5,  # Kernel width for momentum field\n            'sigmaB': 1.2,  # Kernel width for backward map\n            'sigmaA': 1.2,  # Kernel width for forward map\n            'epV': 500,     # Regularization parameter\n        }\n\n    # Check for GPU availability and set device\n    if torch.cuda.is_available():\n        params['device'] = 'cuda:0'\n        print(\"Using GPU for LDDMM calculation\")\n    else:\n        params['device'] = 'cpu'\n        print(\"Using CPU for LDDMM calculation (this may be slow)\")\n\n    # Run LDDMM\n    print(\"Running LDDMM alignment...\")\n    output = STalign.LDDMM(\n        source_grid,  # [Y_source, X_source]\n        source_intensity,\n        target_grid,  # [Y_target, X_target]\n        target_intensity,\n        **params\n    )\n\n    print(\"LDDMM alignment complete\")\n    return output\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#lddmm-parameters-explained","title":"LDDMM Parameters Explained","text":"Parameter Description Default Recommended Range <code>niter</code> Maximum iterations for optimization 1000 500-2000 <code>diffeo_start</code> When to start diffeomorphic transformation 50 20-100 <code>sigmaM</code> Kernel width for momentum field 0.5 0.1-1.0 <code>sigmaB</code> Kernel width for backward map 1.2 0.5-2.0 <code>sigmaA</code> Kernel width for forward map 1.2 0.5-2.0 <code>epV</code> Regularization parameter 500 100-1000 <code>device</code> Computation device 'cpu' 'cpu' or 'cuda:0'"},{"location":"xenium_metabolomics_alignment/#step-5-transforming-point-coordinates","title":"Step 5: Transforming Point Coordinates","text":"<p>After obtaining the LDDMM transformation, apply it to transform the original spatial metabolomics coordinates:</p> <pre><code>def transform_points(lddmm_output, source_coordinates):\n    \"\"\"\n    Transform source coordinates using LDDMM output\n\n    Parameters:\n    -----------\n    lddmm_output : dict\n        Output from the LDDMM alignment\n    source_coordinates : numpy.ndarray\n        Original source coordinates to transform (shape: n x 2)\n\n    Returns:\n    --------\n    numpy.ndarray\n        Transformed coordinates (shape: n x 2)\n    \"\"\"\n    # Extract transformation parameters\n    A = lddmm_output['A']\n    v = lddmm_output['v']\n    xv = lddmm_output['xv']\n\n    # Ensure device is set correctly for tensor operations\n    if torch.cuda.is_available():\n        torch.set_default_device('cuda:0')\n    else:\n        torch.set_default_device('cpu')\n\n    # Stack y and x coordinates (note the order for STalign)\n    stacked_coords = np.stack([source_coordinates[:, 1], source_coordinates[:, 0]], axis=1)\n\n    # Apply transformation\n    transformed_points = STalign.transform_points_source_to_target(xv, v, A, stacked_coords)\n    transformed_points = transformed_points.cpu().numpy()\n\n    # Return as [x, y] format\n    return np.column_stack([transformed_points[:, 1], transformed_points[:, 0]])\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#step-6-visualizing-alignment-results","title":"Step 6: Visualizing Alignment Results","text":"<p>Visualize the alignment to assess quality:</p> <pre><code>def visualize_alignment(xenium_coords, transformed_met_coords, output_path=None):\n    \"\"\"\n    Visualize the alignment between Xenium and transformed metabolomics data\n\n    Parameters:\n    -----------\n    xenium_coords : numpy.ndarray\n        Xenium cell coordinates (shape: n x 2)\n    transformed_met_coords : numpy.ndarray\n        Transformed metabolomics coordinates (shape: m x 2)\n    output_path : str, optional\n        Path to save the visualization\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(12, 10))\n\n    # Plot Xenium coordinates\n    ax.scatter(\n        xenium_coords[:, 0], xenium_coords[:, 1],\n        s=0.3, alpha=0.5, label='Xenium', color='blue'\n    )\n\n    # Plot transformed metabolomics coordinates\n    ax.scatter(\n        transformed_met_coords[:, 0], transformed_met_coords[:, 1],\n        s=0.2, alpha=0.4, label='Transformed Metabolomics', color='orange'\n    )\n\n    ax.set_xlabel('X coordinate')\n    ax.set_ylabel('Y coordinate')\n    ax.set_title('Alignment of Xenium and Spatial Metabolomics Data')\n    ax.legend()\n    ax.grid(True)\n\n    if output_path:\n        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n\n    plt.show()\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#step-7-saving-transformed-coordinates","title":"Step 7: Saving Transformed Coordinates","text":"<p>Save the transformed coordinates along with the original data:</p> <pre><code>def save_transformed_data(original_data, transformed_coords, output_path):\n    \"\"\"\n    Save the original data with transformed coordinates\n\n    Parameters:\n    -----------\n    original_data : pandas.DataFrame\n        Original data with features\n    transformed_coords : numpy.ndarray\n        Transformed coordinates (shape: n x 2)\n    output_path : str\n        Path to save the combined data\n    \"\"\"\n    # Ensure the number of rows match\n    assert len(original_data) == len(transformed_coords), \"Number of coordinates doesn't match data rows\"\n\n    # Create a copy of the original data\n    result_df = original_data.copy()\n\n    # Add transformed coordinates\n    result_df['x_transformed'] = transformed_coords[:, 0]\n    result_df['y_transformed'] = transformed_coords[:, 1]\n\n    # Save to CSV\n    result_df.to_csv(output_path, index=False)\n    print(f\"Saved transformed data to {output_path}\")\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#complete-workflow-example","title":"Complete Workflow Example","text":"<p>Here's a complete example that performs all the steps:</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport STalign\nimport os\n\n# Step 1: Read data\nmet_file = \"path/to/metabolomics_data.csv\"\nxenium_file = \"path/to/xenium_data.csv\"\n\n# Create output directory\noutput_dir = \"alignment_results\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Read metabolomics data\nmet_coords, met_data, mz_values = read_sm_matrix(met_file)\n\n# Read Xenium data\nxenium_coords, xenium_data = read_xenium_data(xenium_file)\n\n# Step 2: Visualize before alignment\nplot_non_zero_coordinates(met_coords, met_data, \"Spatial Metabolomics Coordinates\")\nplot_non_zero_coordinates(xenium_coords, xenium_data, \"Xenium Cell Coordinates\")\n\n# Step 3: Rasterize both datasets\n# Experiment with different pixel sizes\npixel_size = 30  # in the same units as your coordinates (usually \u00b5m)\nX_met, Y_met, intensity_met, _ = rasterize_coordinates(\n    met_coords[:, 0], met_coords[:, 1], pixel_size\n)\nX_xenium, Y_xenium, intensity_xenium, _ = rasterize_coordinates(\n    xenium_coords[:, 0], xenium_coords[:, 1], pixel_size\n)\n\n# Step 4: Run LDDMM alignment\n# Customize parameters based on your data\nlddmm_params = {\n    'niter': 1000,\n    'diffeo_start': 50,\n    'sigmaM': 0.5,\n    'sigmaB': 1.2,\n    'sigmaA': 1.2,\n    'epV': 500,\n}\n\nlddmm_output = run_lddmm_alignment(\n    [Y_met, X_met], [Y_xenium, X_xenium],\n    intensity_met, intensity_xenium,\n    params=lddmm_params\n)\n\n# Step 5: Transform metabolomics coordinates\ntransformed_met_coords = transform_points(lddmm_output, met_coords)\n\n# Step 6: Visualize alignment results\noutput_plot_path = os.path.join(output_dir, \"xenium_metabolomics_alignment.png\")\nvisualize_alignment(xenium_coords, transformed_met_coords, output_plot_path)\n\n# Step 7: Save transformed data\noutput_data_path = os.path.join(output_dir, \"metabolomics_transformed.csv\")\nsave_transformed_data(met_data, transformed_met_coords, output_data_path)\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#optimization-tips","title":"Optimization Tips","text":""},{"location":"xenium_metabolomics_alignment/#tuning-the-lddmm-parameters","title":"Tuning the LDDMM Parameters","text":"<ol> <li>Pixel Size (dx): </li> <li>Start with a moderate value (20-50\u00b5m) </li> <li>Too small: Sparse representation</li> <li>Too large: Loss of detail</li> <li> <p>Optimal: Balances detail and computational efficiency</p> </li> <li> <p>sigmaM, sigmaB, sigmaA (Kernel Width Parameters):</p> </li> <li>Control the smoothness of the transformation</li> <li>Smaller values: Allow more local deformations</li> <li>Larger values: More global transformation, less flexibility</li> <li> <p>Recommended approach: Start with defaults, then adjust if alignment quality is poor</p> </li> <li> <p>epV (Regularization Parameter):</p> </li> <li>Controls the trade-off between data fitting and transformation smoothness</li> <li>Higher values: Smoother, more conservative transformations</li> <li>Lower values: More aggressive fitting, potentially more distortion</li> <li>Start with 500, increase if the transformation appears too distorted</li> </ol>"},{"location":"xenium_metabolomics_alignment/#gpu-vs-cpu-performance","title":"GPU vs. CPU Performance","text":"<ul> <li>For large datasets (&gt;10,000 points), GPU acceleration is strongly recommended</li> <li>With GPU: Minutes to tens of minutes</li> <li>Without GPU: Hours to days for large datasets</li> </ul>"},{"location":"xenium_metabolomics_alignment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"xenium_metabolomics_alignment/#common-issues","title":"Common Issues","text":"<ol> <li>Poor Alignment Quality</li> <li>Check initial data quality and preprocessing</li> <li>Try different pixel sizes for rasterization</li> <li>Adjust LDDMM parameters, particularly sigmaM and epV</li> <li> <p>Consider a rough manual pre-alignment if datasets are severely misaligned</p> </li> <li> <p>Memory Errors</p> </li> <li>Reduce rasterization resolution (increase pixel size)</li> <li>Process subsets of the data</li> <li> <p>Use a machine with more GPU memory</p> </li> <li> <p>Inverted or Flipped Alignment</p> </li> <li>Pre-process your data to ensure consistent orientation</li> <li> <p>Try flipping one dataset before alignment</p> </li> <li> <p>Alignment Fails to Converge</p> </li> <li>Increase the number of iterations (niter)</li> <li>Try a simpler transformation first, then use that as initialization</li> <li>Check for outliers in your data</li> </ol>"},{"location":"xenium_metabolomics_alignment/#integration-with-smint","title":"Integration with SMINT","text":"<p>The SMINT package simplifies this entire process with a single function:</p> <pre><code>from smint.alignment import align_xenium_to_metabolomics\n\n# Simple usage\naligned_data = align_xenium_to_metabolomics(\n    xenium_file=\"path/to/xenium_data.csv\",\n    metabolomics_file=\"path/to/metabolomics_data.csv\",\n    output_dir=\"alignment_results\",\n    pixel_size=30,\n    visualize=True\n)\n\n# Advanced usage with custom parameters\naligned_data = align_xenium_to_metabolomics(\n    xenium_file=\"path/to/xenium_data.csv\",\n    metabolomics_file=\"path/to/metabolomics_data.csv\",\n    output_dir=\"alignment_results\",\n    pixel_size=30,\n    xenium_x_col=\"x_centroid\",\n    xenium_y_col=\"y_centroid\",\n    met_x_col=\"x\",\n    met_y_col=\"y\",\n    lddmm_params={\n        'niter': 1500,\n        'sigmaM': 0.3,\n        'epV': 600\n    },\n    visualize=True,\n    save_intermediate=True\n)\n</code></pre>"},{"location":"xenium_metabolomics_alignment/#references","title":"References","text":"<ol> <li> <p>Levy-Jurgenson, A., Fei, D., Xia, S.Y. et al. STORM: Super Tissue Object Reconstruction in Medicine\u2014a toolkit for multiplex fluorescence spatial proteomics. Cell 186, 2547\u20132566.e17 (2023). DOI: 10.1016/j.cell.2023.04.015</p> </li> <li> <p>Fu, Y., Fan, J. STalign: Align spatial transcriptomics data across multiple platforms. bioRxiv. DOI: 10.1101/2023.09.11.557230</p> </li> <li> <p>10x Genomics Xenium documentation: https://www.10xgenomics.com/products/xenium-in-situ</p> </li> </ol>"},{"location":"api/alignment/","title":"Alignment API","text":"<p>The alignment module provides functions for aligning spatial omics data using ST Align.</p>"},{"location":"api/alignment/#overview","title":"Overview","text":"<p>The alignment module includes the following key functionalities:</p> <ul> <li>run_alignment: Run the ST Align algorithm to align spatial omics data</li> <li>transform_coordinates: Apply transformation to coordinates based on alignment results</li> <li>create_config: Create a configuration file for the ST Align algorithm</li> <li>validate_alignment: Validate alignment results using quality metrics</li> <li>align_xenium_to_metabolomics: Align 10X Xenium data to spatial metabolomics data using LDDMM</li> </ul>"},{"location":"api/alignment/#function-reference","title":"Function Reference","text":"<pre><code>def run_alignment(source_data, target_data, config=None, method=\"similarity\"):\n    \"\"\"\n    Run ST Align to align source data to target data.\n\n    Parameters\n    ----------\n    source_data : str or DataFrame\n        Path to source data CSV or DataFrame\n    target_data : str or DataFrame\n        Path to target data CSV or DataFrame\n    config : dict, optional\n        Configuration parameters for ST Align\n    method : str, optional\n        Transformation method, one of \"rigid\", \"similarity\", \"affine\", \"projective\"\n\n    Returns\n    -------\n    dict\n        Dictionary containing transformation matrix and alignment metrics\n    \"\"\"\n    pass\n\ndef transform_coordinates(coordinates, transformation_matrix):\n    \"\"\"\n    Transform coordinates using a transformation matrix.\n\n    Parameters\n    ----------\n    coordinates : DataFrame or array-like\n        Coordinates to transform\n    transformation_matrix : array-like\n        Transformation matrix from alignment\n\n    Returns\n    -------\n    DataFrame or array-like\n        Transformed coordinates\n    \"\"\"\n    pass\n\ndef create_config(parameters=None):\n    \"\"\"\n    Create a configuration dictionary for ST Align.\n\n    Parameters\n    ----------\n    parameters : dict, optional\n        Custom parameters to override defaults\n\n    Returns\n    -------\n    dict\n        Configuration dictionary\n    \"\"\"\n    pass\n\ndef validate_alignment(source_transformed, target, metrics=None):\n    \"\"\"\n    Validate alignment results using quality metrics.\n\n    Parameters\n    ----------\n    source_transformed : DataFrame\n        Transformed source coordinates\n    target : DataFrame\n        Target coordinates\n    metrics : list, optional\n        Metrics to calculate\n\n    Returns\n    -------\n    dict\n        Dictionary of quality metrics\n    \"\"\"\n    pass\n\n# Xenium-Metabolomics Alignment\n\ndef align_xenium_to_metabolomics(xenium_file, metabolomics_file, output_dir=\"alignment_results\", \n                                pixel_size=30, xenium_x_col=\"x_centroid\", xenium_y_col=\"y_centroid\", \n                                met_x_col=\"x\", met_y_col=\"y\", lddmm_params=None, \n                                visualize=True, save_intermediate=False):\n    \"\"\"\n    Align Xenium spatial transcriptomics data to spatial metabolomics data using LDDMM.\n\n    Parameters\n    ----------\n    xenium_file : str\n        Path to the Xenium coordinate file\n    metabolomics_file : str\n        Path to the metabolomics matrix file\n    output_dir : str, optional\n        Directory to save alignment results\n    pixel_size : float, optional\n        Size of pixels for rasterization\n    xenium_x_col : str, optional\n        Column name for Xenium x coordinates\n    xenium_y_col : str, optional\n        Column name for Xenium y coordinates\n    met_x_col : str, optional\n        Column name for metabolomics x coordinates\n    met_y_col : str, optional\n        Column name for metabolomics y coordinates\n    lddmm_params : dict, optional\n        Parameters for LDDMM algorithm\n    visualize : bool, optional\n        Whether to generate visualization plots\n    save_intermediate : bool, optional\n        Whether to save intermediate results\n\n    Returns\n    -------\n    pandas.DataFrame\n        Metabolomics data with transformed coordinates added\n    \"\"\"\n    pass\n\ndef read_xenium_data(xenium_file, x_col='x_centroid', y_col='y_centroid', verbose=True):\n    \"\"\"\n    Read 10X Xenium data and extract cell coordinates.\n\n    Parameters\n    ----------\n    xenium_file : str\n        Path to the Xenium coordinate file\n    x_col : str, optional\n        Column name for x coordinates\n    y_col : str, optional\n        Column name for y coordinates\n    verbose : bool, optional\n        Whether to print progress information\n\n    Returns\n    -------\n    tuple\n        (coordinates, data)\n        coordinates: numpy.ndarray with shape (n, 2)\n        data: pandas.DataFrame with all data\n    \"\"\"\n    pass\n\ndef read_sm_matrix(mtx_file, x_col='x', y_col='y', verbose=True):\n    \"\"\"\n    Read a Spatial Metabolomics matrix file and extract coordinates and data.\n\n    Parameters\n    ----------\n    mtx_file : str\n        Path to the metabolomics matrix file\n    x_col : str, optional\n        Column name for x coordinates\n    y_col : str, optional\n        Column name for y coordinates\n    verbose : bool, optional\n        Whether to print progress information\n\n    Returns\n    -------\n    tuple\n        (coordinates, data, numeric_columns)\n        coordinates: numpy.ndarray with shape (n, 2)\n        data: pandas.DataFrame with all data\n        numeric_columns: list of numeric column names (m/z values)\n    \"\"\"\n    pass\n\ndef visualize_alignment(xenium_coords, transformed_met_coords, \n                       xenium_label=\"Xenium\", met_label=\"Metabolomics\", \n                       output_path=None):\n    \"\"\"\n    Visualize the alignment between Xenium and transformed metabolomics data.\n\n    Parameters\n    ----------\n    xenium_coords : numpy.ndarray\n        Xenium cell coordinates (shape: n x 2)\n    transformed_met_coords : numpy.ndarray\n        Transformed metabolomics coordinates (shape: m x 2)\n    xenium_label : str, optional\n        Label for Xenium data in legend\n    met_label : str, optional\n        Label for metabolomics data in legend\n    output_path : str, optional\n        Path to save the visualization\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        The created figure\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/alignment/#dependency-handling","title":"Dependency Handling","text":"<p>The alignment module has several optional dependencies:</p> Dependency Required For Fallback Behavior rpy2 R bridge functionality Stub implementation with helpful error messages pandas Data manipulation Required dependency numpy Matrix operations Required dependency matplotlib Visualization Limited visualization capabilities torch GPU acceleration for LDDMM CPU-only operations (slower) STalign Xenium-Metabolomics alignment Functionality unavailable with informative error messages <p>When a dependency is missing, SMINT will log a warning but continue to operate with limited functionality. In the case of the Xenium-Metabolomics alignment, the <code>torch</code> and <code>STalign</code> packages are required, but their absence is gracefully handled so that other parts of the SMINT package can still function.</p>"},{"location":"api/preprocessing/","title":"Preprocessing API","text":"<p>The preprocessing module provides functions for preparing and transforming spatial omics data for analysis.</p>"},{"location":"api/preprocessing/#overview","title":"Overview","text":"<p>The preprocessing module includes the following key functionalities:</p> <ul> <li>split_large_ometiff: Split a large OME-TIFF file into smaller chunks</li> <li>extract_channels: Extract specific channels from an OME-TIFF file</li> <li>normalize_expression: Normalize expression data for analysis</li> <li>scale_data: Scale data to a specific range</li> </ul>"},{"location":"api/preprocessing/#function-reference","title":"Function Reference","text":"<pre><code>def split_large_ometiff(file_path, output_dir, chunk_size=(2048, 2048)):\n    \"\"\"\n    Split a large OME-TIFF file into smaller chunks.\n\n    Parameters\n    ----------\n    file_path : str\n        Path to the input OME-TIFF file\n    output_dir : str\n        Directory to save the output chunks\n    chunk_size : tuple, optional\n        Size of chunks (height, width)\n\n    Returns\n    -------\n    dict\n        Information about the chunking process\n    \"\"\"\n    pass\n\ndef extract_channels(file_path, output_path, channels=None):\n    \"\"\"\n    Extract specific channels from an OME-TIFF file.\n\n    Parameters\n    ----------\n    file_path : str\n        Path to the input OME-TIFF file\n    output_path : str\n        Path to save the extracted channels\n    channels : list, optional\n        List of channel indices to extract\n\n    Returns\n    -------\n    dict\n        Information about the extraction process\n    \"\"\"\n    pass\n\ndef normalize_expression(data, method=\"log1p\", scale_factor=10000):\n    \"\"\"\n    Normalize expression data for analysis.\n\n    Parameters\n    ----------\n    data : DataFrame or array-like\n        Expression data to normalize\n    method : str, optional\n        Normalization method\n    scale_factor : float, optional\n        Scale factor for normalization\n\n    Returns\n    -------\n    DataFrame or array-like\n        Normalized data\n    \"\"\"\n    pass\n\ndef scale_data(data, feature_range=(0, 1), axis=0):\n    \"\"\"\n    Scale data to a specific range.\n\n    Parameters\n    ----------\n    data : DataFrame or array-like\n        Data to scale\n    feature_range : tuple, optional\n        Range to scale to\n    axis : int, optional\n        Axis along which to scale\n\n    Returns\n    -------\n    DataFrame or array-like\n        Scaled data\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/preprocessing/#dependency-handling","title":"Dependency Handling","text":"<p>The preprocessing module relies on several libraries for optimal performance, but can operate with limited functionality when some dependencies are missing:</p> Dependency Required For Fallback Behavior tifffile OME-TIFF reading/writing Stub implementation with helpful error messages scikit-image Image transformations Limited image processing capabilities OpenCV (cv2) Fast image I/O Slower fallback implementation <p>When a dependency is missing, SMINT will log a warning but continue to operate with limited functionality.</p>"},{"location":"api/r_integration/","title":"R Integration API","text":"<p>The R integration module provides functions for calling R scripts and functions from Python and for transferring data between Python and R.</p>"},{"location":"api/r_integration/#overview","title":"Overview","text":"<p>The R integration module includes the following key functionalities:</p> <ul> <li>run_r_script: Run an R script from Python</li> <li>initialize_r: Initialize the R environment</li> <li>r_to_pandas: Convert R objects to pandas DataFrames</li> <li>pandas_to_r: Convert pandas DataFrames to R objects</li> <li>run_r_function: Call R functions from Python</li> </ul>"},{"location":"api/r_integration/#function-reference","title":"Function Reference","text":"<pre><code>def run_r_script(script_path, args=None, return_output=False):\n    \"\"\"\n    Run an R script from Python.\n\n    Parameters\n    ----------\n    script_path : str\n        Path to the R script\n    args : list, optional\n        Command line arguments to pass to the R script\n    return_output : bool, optional\n        Whether to return the script's output\n\n    Returns\n    -------\n    str or None\n        Output of the R script if return_output is True\n    \"\"\"\n    pass\n\ndef initialize_r(packages=None):\n    \"\"\"\n    Initialize the R environment.\n\n    Parameters\n    ----------\n    packages : list, optional\n        List of R packages to load\n\n    Returns\n    -------\n    bool\n        Whether initialization was successful\n    \"\"\"\n    pass\n\ndef r_to_pandas(r_object):\n    \"\"\"\n    Convert R objects to pandas DataFrames.\n\n    Parameters\n    ----------\n    r_object : rpy2.robjects.vectors.DataFrame or str\n        R DataFrame object or name of R object\n\n    Returns\n    -------\n    pandas.DataFrame\n        Pandas DataFrame\n    \"\"\"\n    pass\n\ndef pandas_to_r(df, r_variable_name=None):\n    \"\"\"\n    Convert pandas DataFrames to R objects.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Pandas DataFrame to convert\n    r_variable_name : str, optional\n        Name to assign to the R object\n\n    Returns\n    -------\n    rpy2.robjects.vectors.DataFrame\n        R DataFrame object\n    \"\"\"\n    pass\n\ndef run_r_function(function_name, *args, **kwargs):\n    \"\"\"\n    Call R functions from Python.\n\n    Parameters\n    ----------\n    function_name : str\n        Name of the R function to call\n    *args : tuple\n        Positional arguments to pass to the R function\n    **kwargs : dict\n        Keyword arguments to pass to the R function\n\n    Returns\n    -------\n    object\n        Result of the R function call\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/r_integration/#dependency-handling","title":"Dependency Handling","text":"<p>The R integration module has several optional dependencies:</p> Dependency Required For Fallback Behavior rpy2 Direct R integration Fallback to subprocess R script execution pandas Data manipulation Required dependency numpy Matrix operations Required dependency R R script execution Required for any R functionality <p>When rpy2 is missing, SMINT will still allow you to run R scripts through subprocess calls, but the direct function calling and data transfer capabilities will be limited.</p>"},{"location":"api/segmentation/","title":"Segmentation API","text":"<p>The segmentation module provides functions for segmenting cells and nuclei in whole-slide images.</p>"},{"location":"api/segmentation/#core-segmentation-functions","title":"Core Segmentation Functions","text":"<p>::: smint.segmentation.process_large_image     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p> <p>::: smint.segmentation.run_distributed_segmentation     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p>"},{"location":"api/segmentation/#cell-utilities","title":"Cell Utilities","text":"<p>::: smint.segmentation.get_cell_outlines     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p> <p>::: smint.segmentation.segment_chunk     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p>"},{"location":"api/segmentation/#post-processing","title":"Post-processing","text":"<p>::: smint.segmentation.extract_contours     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p> <p>::: smint.segmentation.save_masks     options:       show_root_heading: true       show_source: true       show_signature_annotations: true</p>"},{"location":"api/segmentation/#optional-dependencies","title":"Optional Dependencies","text":"<p>The segmentation module has several optional dependencies:</p> Dependency Required For Fallback Behavior Cellpose Cell segmentation models Stub implementation with helpful error messages OpenCV (cv2) Image I/O and contour extraction Limited visualization, no mask saving/loading Dask Distributed processing Single-process implementation only Distributed Multi-node computation Single-node implementation only CUDA GPU acceleration CPU-only implementation <p>When a dependency is missing, SMINT will log a warning but continue to operate with limited functionality.</p>"},{"location":"api/utils/","title":"Utilities API","text":"<p>The utilities module provides helper functions for file operations, logging, and other common tasks.</p>"},{"location":"api/utils/#overview","title":"Overview","text":"<p>The utilities module includes the following key functionalities:</p> <ul> <li>list_files: List files in a directory with optional filtering</li> <li>create_directory: Create a directory if it doesn't exist</li> <li>get_file_info: Get information about a file</li> <li>setup_logger: Set up a logger for consistent logging</li> <li>log_parameters: Log parameters for reproducibility</li> <li>load_config: Load configuration from a file</li> <li>save_config: Save configuration to a file</li> </ul>"},{"location":"api/utils/#function-reference","title":"Function Reference","text":"<pre><code>def list_files(directory, pattern=None, recursive=False):\n    \"\"\"\n    List files in a directory with optional filtering.\n\n    Parameters\n    ----------\n    directory : str\n        Directory to list files from\n    pattern : str, optional\n        Glob pattern to filter files\n    recursive : bool, optional\n        Whether to search recursively\n\n    Returns\n    -------\n    list\n        List of file paths\n    \"\"\"\n    pass\n\ndef create_directory(directory, parents=True, exist_ok=True):\n    \"\"\"\n    Create a directory if it doesn't exist.\n\n    Parameters\n    ----------\n    directory : str\n        Directory to create\n    parents : bool, optional\n        Whether to create parent directories\n    exist_ok : bool, optional\n        Whether to ignore if directory exists\n\n    Returns\n    -------\n    str\n        Path to created directory\n    \"\"\"\n    pass\n\ndef get_file_info(file_path):\n    \"\"\"\n    Get information about a file.\n\n    Parameters\n    ----------\n    file_path : str\n        Path to the file\n\n    Returns\n    -------\n    dict\n        Dictionary with file information\n    \"\"\"\n    pass\n\ndef setup_logger(name, log_file=None, level=logging.INFO, format=None):\n    \"\"\"\n    Set up a logger for consistent logging.\n\n    Parameters\n    ----------\n    name : str\n        Name of the logger\n    log_file : str, optional\n        Path to log file\n    level : int, optional\n        Logging level\n    format : str, optional\n        Log message format\n\n    Returns\n    -------\n    logging.Logger\n        Configured logger\n    \"\"\"\n    pass\n\ndef log_parameters(logger, parameters, prefix=''):\n    \"\"\"\n    Log parameters for reproducibility.\n\n    Parameters\n    ----------\n    logger : logging.Logger\n        Logger to use\n    parameters : dict\n        Parameters to log\n    prefix : str, optional\n        Prefix for parameter names\n\n    Returns\n    -------\n    None\n    \"\"\"\n    pass\n\ndef load_config(config_path, format=None):\n    \"\"\"\n    Load configuration from a file.\n\n    Parameters\n    ----------\n    config_path : str\n        Path to configuration file\n    format : str, optional\n        Format of the file (yaml, json, etc.)\n\n    Returns\n    -------\n    dict\n        Configuration dictionary\n    \"\"\"\n    pass\n\ndef save_config(config, config_path, format=None):\n    \"\"\"\n    Save configuration to a file.\n\n    Parameters\n    ----------\n    config : dict\n        Configuration dictionary\n    config_path : str\n        Path to save configuration to\n    format : str, optional\n        Format to save in (yaml, json, etc.)\n\n    Returns\n    -------\n    str\n        Path to saved configuration\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/utils/#dependency-handling","title":"Dependency Handling","text":"<p>The utilities module is designed to have minimal external dependencies, making it more robust across different environments. The core functionality requires only standard Python libraries, with some enhanced features available when optional dependencies are present.</p> Dependency Required For Fallback Behavior PyYAML Advanced config loading/saving Fallback to JSON for configuration tqdm Progress tracking Simple text-based progress updates pandas Data manipulation Limited data handling capabilities <p>The utilities module is designed to be a reliable foundation for the rest of the SMINT package, with minimal external dependencies to ensure robustness.</p>"},{"location":"api/visualization/","title":"Visualization API","text":"<p>The visualization module provides functions for visualizing segmentation results and spatial data.</p>"},{"location":"api/visualization/#overview","title":"Overview","text":"<p>The visualization module includes the following key functionalities:</p> <ul> <li>create_rgb_composite: Create an RGB composite image from multiple channels</li> <li>visualize_segmentation_overlay: Overlay segmentation results on an image</li> <li>visualize_cell_outlines: Visualize cell outlines on an image</li> <li>plot_cell_features: Plot cell features as a heatmap</li> <li>create_segmentation_animation: Create an animation of segmentation results</li> <li>LiveScanViewer: Interactive viewer for live segmentation results</li> </ul>"},{"location":"api/visualization/#function-reference","title":"Function Reference","text":"<pre><code>def create_rgb_composite(image_data, channel_indices=(0, 1, 2), normalize=True):\n    \"\"\"\n    Create an RGB composite image from multiple channels.\n\n    Parameters\n    ----------\n    image_data : ndarray\n        Multi-channel image data with shape (C, H, W)\n    channel_indices : tuple, optional\n        Indices of channels to use for RGB channels\n    normalize : bool, optional\n        Whether to normalize each channel\n\n    Returns\n    -------\n    ndarray\n        RGB composite image with shape (H, W, 3)\n    \"\"\"\n    pass\n\ndef visualize_segmentation_overlay(image, segmentation_mask, alpha=0.5, colors=None):\n    \"\"\"\n    Overlay segmentation results on an image.\n\n    Parameters\n    ----------\n    image : ndarray\n        Background image\n    segmentation_mask : ndarray\n        Segmentation mask with unique IDs for each object\n    alpha : float, optional\n        Transparency of the overlay\n    colors : ndarray, optional\n        Color map for segmentation mask\n\n    Returns\n    -------\n    ndarray\n        Image with segmentation overlay\n    \"\"\"\n    pass\n\ndef visualize_cell_outlines(image, cell_outlines, color=(1, 0, 0), thickness=2):\n    \"\"\"\n    Visualize cell outlines on an image.\n\n    Parameters\n    ----------\n    image : ndarray\n        Background image\n    cell_outlines : list\n        List of cell outline coordinates\n    color : tuple, optional\n        RGB color for outlines\n    thickness : int, optional\n        Thickness of outline lines\n\n    Returns\n    -------\n    ndarray\n        Image with cell outlines\n    \"\"\"\n    pass\n\ndef plot_cell_features(cell_data, feature_name, image=None, colormap='viridis'):\n    \"\"\"\n    Plot cell features as a heatmap.\n\n    Parameters\n    ----------\n    cell_data : DataFrame\n        Cell data with coordinates and features\n    feature_name : str\n        Name of feature to plot\n    image : ndarray, optional\n        Background image\n    colormap : str, optional\n        Color map for heatmap\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        Figure with cell feature plot\n    \"\"\"\n    pass\n\ndef create_segmentation_animation(image_sequence, mask_sequence, output_path, fps=5):\n    \"\"\"\n    Create an animation of segmentation results.\n\n    Parameters\n    ----------\n    image_sequence : list\n        List of background images\n    mask_sequence : list\n        List of segmentation masks\n    output_path : str\n        Path to save animation\n    fps : int, optional\n        Frames per second\n\n    Returns\n    -------\n    str\n        Path to saved animation\n    \"\"\"\n    pass\n\nclass LiveScanViewer:\n    \"\"\"\n    Interactive viewer for live segmentation results.\n\n    Parameters\n    ----------\n    master : tkinter.Tk\n        Tkinter master window\n    full_scan_path : str\n        Path to full scan image\n    segmentation_history_dir : str\n        Directory containing segmentation history\n    tile_info_path : str\n        Path to tile information file\n    update_interval_ms : int, optional\n        Update interval in milliseconds\n\n    Methods\n    -------\n    start()\n        Start the viewer\n    update_views()\n        Update all views\n    show_next_segmentation()\n        Show next segmentation result\n    show_previous_segmentation()\n        Show previous segmentation result\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/visualization/#dependency-handling","title":"Dependency Handling","text":"<p>The visualization module has several optional dependencies:</p> Dependency Required For Fallback Behavior matplotlib All plotting functionality Stub implementation with helpful error messages OpenCV (cv2) Image I/O and processing Limited visualization capabilities tkinter Live Scan Viewer GUI Command-line only interface numpy Data manipulation Required dependency <p>When a dependency is missing, SMINT will log a warning but continue to operate with limited functionality.</p>"}]}